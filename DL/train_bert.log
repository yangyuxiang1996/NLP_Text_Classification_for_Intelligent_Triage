nohup: ignoring input
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2021-08-23 19:34:35 train.py INFO 加载数据......
2021-08-23 19:34:36 configuration_utils.py INFO loading configuration file /home/user10000761/notespace/Chinese-Text-Classification/DL/pretrained_model/bert-base-chinese/config.json
2021-08-23 19:34:36 configuration_utils.py INFO Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.3,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

2021-08-23 19:34:36 tokenization_utils.py INFO Model name '/home/user10000761/notespace/Chinese-Text-Classification/DL/pretrained_model/bert-base-chinese' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming '/home/user10000761/notespace/Chinese-Text-Classification/DL/pretrained_model/bert-base-chinese' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-08-23 19:34:36 tokenization_utils.py INFO Didn't find file /home/user10000761/notespace/Chinese-Text-Classification/DL/pretrained_model/bert-base-chinese/added_tokens.json. We won't load it.
2021-08-23 19:34:36 tokenization_utils.py INFO Didn't find file /home/user10000761/notespace/Chinese-Text-Classification/DL/pretrained_model/bert-base-chinese/special_tokens_map.json. We won't load it.
2021-08-23 19:34:36 tokenization_utils.py INFO Didn't find file /home/user10000761/notespace/Chinese-Text-Classification/DL/pretrained_model/bert-base-chinese/tokenizer_config.json. We won't load it.
2021-08-23 19:34:36 tokenization_utils.py INFO loading file /home/user10000761/notespace/Chinese-Text-Classification/DL/pretrained_model/bert-base-chinese/vocab.txt
2021-08-23 19:34:36 tokenization_utils.py INFO loading file None
2021-08-23 19:34:36 tokenization_utils.py INFO loading file None
2021-08-23 19:34:36 tokenization_utils.py INFO loading file None
2021-08-23 19:34:36 modeling_utils.py INFO loading weights file /home/user10000761/notespace/Chinese-Text-Classification/DL/pretrained_model/bert-base-chinese/pytorch_model.bin
2021-08-23 19:34:41 modeling_utils.py INFO Weights of BertModelForMedical not initialized from pretrained model: ['bert.bert_model.bert.embeddings.word_embeddings.weight', 'bert.bert_model.bert.embeddings.position_embeddings.weight', 'bert.bert_model.bert.embeddings.token_type_embeddings.weight', 'bert.bert_model.bert.embeddings.LayerNorm.weight', 'bert.bert_model.bert.embeddings.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.0.attention.self.query.weight', 'bert.bert_model.bert.encoder.layer.0.attention.self.query.bias', 'bert.bert_model.bert.encoder.layer.0.attention.self.key.weight', 'bert.bert_model.bert.encoder.layer.0.attention.self.key.bias', 'bert.bert_model.bert.encoder.layer.0.attention.self.value.weight', 'bert.bert_model.bert.encoder.layer.0.attention.self.value.bias', 'bert.bert_model.bert.encoder.layer.0.attention.output.dense.weight', 'bert.bert_model.bert.encoder.layer.0.attention.output.dense.bias', 'bert.bert_model.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.0.intermediate.dense.weight', 'bert.bert_model.bert.encoder.layer.0.intermediate.dense.bias', 'bert.bert_model.bert.encoder.layer.0.output.dense.weight', 'bert.bert_model.bert.encoder.layer.0.output.dense.bias', 'bert.bert_model.bert.encoder.layer.0.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.0.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.1.attention.self.query.weight', 'bert.bert_model.bert.encoder.layer.1.attention.self.query.bias', 'bert.bert_model.bert.encoder.layer.1.attention.self.key.weight', 'bert.bert_model.bert.encoder.layer.1.attention.self.key.bias', 'bert.bert_model.bert.encoder.layer.1.attention.self.value.weight', 'bert.bert_model.bert.encoder.layer.1.attention.self.value.bias', 'bert.bert_model.bert.encoder.layer.1.attention.output.dense.weight', 'bert.bert_model.bert.encoder.layer.1.attention.output.dense.bias', 'bert.bert_model.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.1.intermediate.dense.weight', 'bert.bert_model.bert.encoder.layer.1.intermediate.dense.bias', 'bert.bert_model.bert.encoder.layer.1.output.dense.weight', 'bert.bert_model.bert.encoder.layer.1.output.dense.bias', 'bert.bert_model.bert.encoder.layer.1.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.1.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.2.attention.self.query.weight', 'bert.bert_model.bert.encoder.layer.2.attention.self.query.bias', 'bert.bert_model.bert.encoder.layer.2.attention.self.key.weight', 'bert.bert_model.bert.encoder.layer.2.attention.self.key.bias', 'bert.bert_model.bert.encoder.layer.2.attention.self.value.weight', 'bert.bert_model.bert.encoder.layer.2.attention.self.value.bias', 'bert.bert_model.bert.encoder.layer.2.attention.output.dense.weight', 'bert.bert_model.bert.encoder.layer.2.attention.output.dense.bias', 'bert.bert_model.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.2.intermediate.dense.weight', 'bert.bert_model.bert.encoder.layer.2.intermediate.dense.bias', 'bert.bert_model.bert.encoder.layer.2.output.dense.weight', 'bert.bert_model.bert.encoder.layer.2.output.dense.bias', 'bert.bert_model.bert.encoder.layer.2.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.2.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.3.attention.self.query.weight', 'bert.bert_model.bert.encoder.layer.3.attention.self.query.bias', 'bert.bert_model.bert.encoder.layer.3.attention.self.key.weight', 'bert.bert_model.bert.encoder.layer.3.attention.self.key.bias', 'bert.bert_model.bert.encoder.layer.3.attention.self.value.weight', 'bert.bert_model.bert.encoder.layer.3.attention.self.value.bias', 'bert.bert_model.bert.encoder.layer.3.attention.output.dense.weight', 'bert.bert_model.bert.encoder.layer.3.attention.output.dense.bias', 'bert.bert_model.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.3.intermediate.dense.weight', 'bert.bert_model.bert.encoder.layer.3.intermediate.dense.bias', 'bert.bert_model.bert.encoder.layer.3.output.dense.weight', 'bert.bert_model.bert.encoder.layer.3.output.dense.bias', 'bert.bert_model.bert.encoder.layer.3.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.3.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.4.attention.self.query.weight', 'bert.bert_model.bert.encoder.layer.4.attention.self.query.bias', 'bert.bert_model.bert.encoder.layer.4.attention.self.key.weight', 'bert.bert_model.bert.encoder.layer.4.attention.self.key.bias', 'bert.bert_model.bert.encoder.layer.4.attention.self.value.weight', 'bert.bert_model.bert.encoder.layer.4.attention.self.value.bias', 'bert.bert_model.bert.encoder.layer.4.attention.output.dense.weight', 'bert.bert_model.bert.encoder.layer.4.attention.output.dense.bias', 'bert.bert_model.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.4.intermediate.dense.weight', 'bert.bert_model.bert.encoder.layer.4.intermediate.dense.bias', 'bert.bert_model.bert.encoder.layer.4.output.dense.weight', 'bert.bert_model.bert.encoder.layer.4.output.dense.bias', 'bert.bert_model.bert.encoder.layer.4.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.4.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.5.attention.self.query.weight', 'bert.bert_model.bert.encoder.layer.5.attention.self.query.bias', 'bert.bert_model.bert.encoder.layer.5.attention.self.key.weight', 'bert.bert_model.bert.encoder.layer.5.attention.self.key.bias', 'bert.bert_model.bert.encoder.layer.5.attention.self.value.weight', 'bert.bert_model.bert.encoder.layer.5.attention.self.value.bias', 'bert.bert_model.bert.encoder.layer.5.attention.output.dense.weight', 'bert.bert_model.bert.encoder.layer.5.attention.output.dense.bias', 'bert.bert_model.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.5.intermediate.dense.weight', 'bert.bert_model.bert.encoder.layer.5.intermediate.dense.bias', 'bert.bert_model.bert.encoder.layer.5.output.dense.weight', 'bert.bert_model.bert.encoder.layer.5.output.dense.bias', 'bert.bert_model.bert.encoder.layer.5.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.5.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.6.attention.self.query.weight', 'bert.bert_model.bert.encoder.layer.6.attention.self.query.bias', 'bert.bert_model.bert.encoder.layer.6.attention.self.key.weight', 'bert.bert_model.bert.encoder.layer.6.attention.self.key.bias', 'bert.bert_model.bert.encoder.layer.6.attention.self.value.weight', 'bert.bert_model.bert.encoder.layer.6.attention.self.value.bias', 'bert.bert_model.bert.encoder.layer.6.attention.output.dense.weight', 'bert.bert_model.bert.encoder.layer.6.attention.output.dense.bias', 'bert.bert_model.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.6.intermediate.dense.weight', 'bert.bert_model.bert.encoder.layer.6.intermediate.dense.bias', 'bert.bert_model.bert.encoder.layer.6.output.dense.weight', 'bert.bert_model.bert.encoder.layer.6.output.dense.bias', 'bert.bert_model.bert.encoder.layer.6.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.6.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.7.attention.self.query.weight', 'bert.bert_model.bert.encoder.layer.7.attention.self.query.bias', 'bert.bert_model.bert.encoder.layer.7.attention.self.key.weight', 'bert.bert_model.bert.encoder.layer.7.attention.self.key.bias', 'bert.bert_model.bert.encoder.layer.7.attention.self.value.weight', 'bert.bert_model.bert.encoder.layer.7.attention.self.value.bias', 'bert.bert_model.bert.encoder.layer.7.attention.output.dense.weight', 'bert.bert_model.bert.encoder.layer.7.attention.output.dense.bias', 'bert.bert_model.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.7.intermediate.dense.weight', 'bert.bert_model.bert.encoder.layer.7.intermediate.dense.bias', 'bert.bert_model.bert.encoder.layer.7.output.dense.weight', 'bert.bert_model.bert.encoder.layer.7.output.dense.bias', 'bert.bert_model.bert.encoder.layer.7.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.7.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.8.attention.self.query.weight', 'bert.bert_model.bert.encoder.layer.8.attention.self.query.bias', 'bert.bert_model.bert.encoder.layer.8.attention.self.key.weight', 'bert.bert_model.bert.encoder.layer.8.attention.self.key.bias', 'bert.bert_model.bert.encoder.layer.8.attention.self.value.weight', 'bert.bert_model.bert.encoder.layer.8.attention.self.value.bias', 'bert.bert_model.bert.encoder.layer.8.attention.output.dense.weight', 'bert.bert_model.bert.encoder.layer.8.attention.output.dense.bias', 'bert.bert_model.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.8.intermediate.dense.weight', 'bert.bert_model.bert.encoder.layer.8.intermediate.dense.bias', 'bert.bert_model.bert.encoder.layer.8.output.dense.weight', 'bert.bert_model.bert.encoder.layer.8.output.dense.bias', 'bert.bert_model.bert.encoder.layer.8.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.8.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.9.attention.self.query.weight', 'bert.bert_model.bert.encoder.layer.9.attention.self.query.bias', 'bert.bert_model.bert.encoder.layer.9.attention.self.key.weight', 'bert.bert_model.bert.encoder.layer.9.attention.self.key.bias', 'bert.bert_model.bert.encoder.layer.9.attention.self.value.weight', 'bert.bert_model.bert.encoder.layer.9.attention.self.value.bias', 'bert.bert_model.bert.encoder.layer.9.attention.output.dense.weight', 'bert.bert_model.bert.encoder.layer.9.attention.output.dense.bias', 'bert.bert_model.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.9.intermediate.dense.weight', 'bert.bert_model.bert.encoder.layer.9.intermediate.dense.bias', 'bert.bert_model.bert.encoder.layer.9.output.dense.weight', 'bert.bert_model.bert.encoder.layer.9.output.dense.bias', 'bert.bert_model.bert.encoder.layer.9.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.9.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.10.attention.self.query.weight', 'bert.bert_model.bert.encoder.layer.10.attention.self.query.bias', 'bert.bert_model.bert.encoder.layer.10.attention.self.key.weight', 'bert.bert_model.bert.encoder.layer.10.attention.self.key.bias', 'bert.bert_model.bert.encoder.layer.10.attention.self.value.weight', 'bert.bert_model.bert.encoder.layer.10.attention.self.value.bias', 'bert.bert_model.bert.encoder.layer.10.attention.output.dense.weight', 'bert.bert_model.bert.encoder.layer.10.attention.output.dense.bias', 'bert.bert_model.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.10.intermediate.dense.weight', 'bert.bert_model.bert.encoder.layer.10.intermediate.dense.bias', 'bert.bert_model.bert.encoder.layer.10.output.dense.weight', 'bert.bert_model.bert.encoder.layer.10.output.dense.bias', 'bert.bert_model.bert.encoder.layer.10.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.10.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.11.attention.self.query.weight', 'bert.bert_model.bert.encoder.layer.11.attention.self.query.bias', 'bert.bert_model.bert.encoder.layer.11.attention.self.key.weight', 'bert.bert_model.bert.encoder.layer.11.attention.self.key.bias', 'bert.bert_model.bert.encoder.layer.11.attention.self.value.weight', 'bert.bert_model.bert.encoder.layer.11.attention.self.value.bias', 'bert.bert_model.bert.encoder.layer.11.attention.output.dense.weight', 'bert.bert_model.bert.encoder.layer.11.attention.output.dense.bias', 'bert.bert_model.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.bert_model.bert.encoder.layer.11.intermediate.dense.weight', 'bert.bert_model.bert.encoder.layer.11.intermediate.dense.bias', 'bert.bert_model.bert.encoder.layer.11.output.dense.weight', 'bert.bert_model.bert.encoder.layer.11.output.dense.bias', 'bert.bert_model.bert.encoder.layer.11.output.LayerNorm.weight', 'bert.bert_model.bert.encoder.layer.11.output.LayerNorm.bias', 'bert.bert_model.bert.pooler.dense.weight', 'bert.bert_model.bert.pooler.dense.bias', 'bert.bert_model.classifier.weight', 'bert.bert_model.classifier.bias', 'bert.fc.weight', 'bert.fc.bias']
2021-08-23 19:34:41 modeling_utils.py INFO Weights from pretrained model not used in BertModelForMedical: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias']
2021-08-23 19:34:51 train.py INFO ***** Running training *****
2021-08-23 19:34:51 train.py INFO   Num examples = 19760
2021-08-23 19:34:51 train.py INFO   Num Epochs = 30
2021-08-23 19:34:51 train.py INFO   batch size = 16
2021-08-23 19:34:51 train.py INFO   Num batches = 37050
2021-08-23 19:34:51 train.py INFO   device: cuda
2021-08-23 19:34:51 train.py INFO Epoch [1/30]
2021-08-23 19:34:52 train.py INFO token_ids: tensor([[ 101, 2111, 2094,  ...,    0,    0,    0],
        [ 101, 2340,  904,  ...,    0,    0,    0],
        [ 101,  872, 1962,  ...,    0,    0,    0],
        ...,
        [ 101, 1377,  809,  ...,    0,    0,    0],
        [ 101, 2769, 1624,  ...,    0,    0,    0],
        [ 101, 1278, 4495,  ..., 5162, 2971,  102]])
 
2021-08-23 19:34:52 train.py INFO token_ids shape: torch.Size([16, 128])
 
2021-08-23 19:34:52 train.py INFO attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1]])

2021-08-23 19:34:52 train.py INFO token_type_ids: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]])

2021-08-23 19:34:52 train.py INFO labels: tensor([7, 0, 7, 0, 6, 8, 4, 1, 6, 8, 1, 7, 3, 2, 8, 6])

2021-08-23 19:34:52 train.py INFO labels shape: torch.Size([16])

2021-08-23 19:39:21 train.py INFO result: 
              precision    recall  f1-score   support

          男科     0.8815    0.8934    0.8874       591
         皮肤科     0.7541    0.7977    0.7753       173
          其它     0.3482    0.4815    0.4041       162
          妇科     0.7949    0.4306    0.5586        72
       心血管内科     0.6912    0.7015    0.6963        67
        耳鼻喉科     0.7879    0.5098    0.6190        51
        消化内科     0.5200    0.7738    0.6220        84
        小儿内科     0.4702    0.6228    0.5358       114
        呼吸内科     0.5795    0.3723    0.4533       137
        内分泌科     0.7101    0.7778    0.7424        63
        神经内科     0.0000    0.0000    0.0000        66

    accuracy                         0.6861      1580
   macro avg     0.5943    0.5783    0.5722      1580
weighted avg     0.6791    0.6861    0.6739      1580

2021-08-23 19:39:21 train.py INFO Confusion matrix: 
[[528  13  38   2   3   0   4   0   2   1   0]
 [ 10 138  17   1   0   0   4   0   0   3   0]
 [ 21  15  78   2   4   1  21   6   8   6   0]
 [  7   5  20  31   1   0   5   1   0   2   0]
 [  4   1   5   0  47   0   5   0   0   4   1]
 [  0   1   6   0   0  26   0   5  13   0   0]
 [  1   1  12   0   1   0  65   1   1   2   0]
 [  0   4  12   3   0   3   7  71  13   1   0]
 [  0   2  12   0   0   3   3  66  51   0   0]
 [  5   0   4   0   5   0   0   0   0  49   0]
 [ 23   3  20   0   7   0  11   1   0   1   0]]
2021-08-23 19:39:23 train.py INFO Iter:1000, Train Loss:1.3544, Train Acc:68.75%, Val Loss:0.9282, Val Acc:68.61%, Time:0:04:41 *
2021-08-23 19:40:24 train.py INFO Epoch [2/30]
2021-08-23 19:40:24 train.py INFO token_ids: tensor([[ 101,  860, 3466,  ...,    0,    0,    0],
        [ 101,  872, 1962,  ...,    0,    0,    0],
        [ 101, 4567, 4568,  ..., 3613, 2458,  102],
        ...,
        [ 101, 2769, 1762,  ...,    0,    0,    0],
        [ 101, 1278, 4495,  ...,    0,    0,    0],
        [ 101, 1278, 4495,  ...,    0,    0,    0]])
 
2021-08-23 19:40:24 train.py INFO token_ids shape: torch.Size([16, 128])
 
2021-08-23 19:40:24 train.py INFO attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]])

2021-08-23 19:40:24 train.py INFO token_type_ids: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]])

2021-08-23 19:40:24 train.py INFO labels: tensor([ 2,  1, 10,  9,  7,  1,  8,  7,  6,  7,  1,  4,  3,  1,  7,  2])

2021-08-23 19:40:24 train.py INFO labels shape: torch.Size([16])

2021-08-23 19:43:49 train.py INFO result: 
              precision    recall  f1-score   support

          男科     0.9896    0.8054    0.8881       591
         皮肤科     0.6776    0.9595    0.7943       173
          其它     0.4140    0.5494    0.4721       162
          妇科     0.6706    0.7917    0.7261        72
       心血管内科     0.8800    0.6567    0.7521        67
        耳鼻喉科     0.7609    0.6863    0.7216        51
        消化内科     0.8209    0.6548    0.7285        84
        小儿内科     0.6800    0.7456    0.7113       114
        呼吸内科     0.7699    0.6350    0.6960       137
        内分泌科     0.8095    0.8095    0.8095        63
        神经内科     0.5222    0.7121    0.6026        66

    accuracy                         0.7544      1580
   macro avg     0.7268    0.7278    0.7184      1580
weighted avg     0.7928    0.7544    0.7637      1580

2021-08-23 19:43:49 train.py INFO Confusion matrix: 
[[476  32  48  19   1   0   1   0   1   2  11]
 [  1 166   3   1   0   1   0   0   0   0   1]
 [  3  24  89   5   1   2   6   7   4   6  15]
 [  0   5  10  57   0   0   0   0   0   0   0]
 [  1   1   9   0  44   0   0   0   2   4   6]
 [  0   3   1   0   0  35   0   3   7   0   2]
 [  0   2  22   0   0   0  55   1   3   0   1]
 [  0   4  10   0   0   1   3  85   9   0   2]
 [  0   4  10   1   0   6   1  28  87   0   0]
 [  0   0   5   1   1   0   0   0   0  51   5]
 [  0   4   8   1   3   1   1   1   0   0  47]]
2021-08-23 19:43:52 train.py INFO Iter:2000, Train Loss:0.5707, Train Acc:87.50%, Val Loss:0.7248, Val Acc:75.44%, Time:0:09:10 *
2021-08-23 19:45:52 train.py INFO Epoch [3/30]
2021-08-23 19:45:52 train.py INFO token_ids: tensor([[  101, 12797,  8175,  ...,     0,     0,     0],
        [  101,  5687,  3996,  ...,     0,     0,     0],
        [  101,  1184,  1154,  ...,     0,     0,     0],
        ...,
        [  101,  2140,  2140,  ...,     0,     0,     0],
        [  101,  1278,  4495,  ...,     0,     0,     0],
        [  101,  7568,  6956,  ...,     0,     0,     0]])
 
2021-08-23 19:45:52 train.py INFO token_ids shape: torch.Size([16, 123])
 
2021-08-23 19:45:52 train.py INFO attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]])

2021-08-23 19:45:52 train.py INFO token_type_ids: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]])

2021-08-23 19:45:52 train.py INFO labels: tensor([ 8,  2,  0,  7,  0,  1,  8,  8,  5, 10,  1,  1,  1,  7,  2,  1])

2021-08-23 19:45:52 train.py INFO labels shape: torch.Size([16])

2021-08-23 19:48:17 train.py INFO result: 
              precision    recall  f1-score   support

          男科     0.9834    0.9036    0.9418       591
         皮肤科     0.7725    0.9422    0.8490       173
          其它     0.6182    0.4198    0.5000       162
          妇科     0.7975    0.8750    0.8344        72
       心血管内科     0.8644    0.7612    0.8095        67
        耳鼻喉科     0.6964    0.7647    0.7290        51
        消化内科     0.8095    0.8095    0.8095        84
        小儿内科     0.6911    0.7456    0.7173       114
        呼吸内科     0.7279    0.7810    0.7535       137
        内分泌科     0.7536    0.8254    0.7879        63
        神经内科     0.5152    0.7727    0.6182        66

    accuracy                         0.8108      1580
   macro avg     0.7482    0.7819    0.7591      1580
weighted avg     0.8189    0.8108    0.8098      1580

2021-08-23 19:48:17 train.py INFO Confusion matrix: 
[[534  17  15   9   0   0   2   2   1   2   9]
 [  2 163   2   1   0   1   1   0   0   1   2]
 [  6  21  68   5   2   5   8  12   7   7  21]
 [  1   1   3  63   0   0   1   0   0   2   1]
 [  0   1   1   0  51   0   0   0   3   5   6]
 [  0   0   0   0   0  39   0   1   9   0   2]
 [  0   0   8   0   1   0  68   2   4   0   1]
 [  0   3   4   0   0   3   2  85  15   0   2]
 [  0   1   1   1   1   7   1  18 107   0   0]
 [  0   0   5   0   2   0   0   0   0  52   4]
 [  0   4   3   0   2   1   1   3   1   0  51]]
2021-08-23 19:48:19 train.py INFO Iter:3000, Train Loss:0.5109, Train Acc:81.25%, Val Loss:0.5882, Val Acc:81.08%, Time:0:13:37 *
2021-08-23 19:51:22 train.py INFO Epoch [4/30]
2021-08-23 19:51:22 train.py INFO token_ids: tensor([[ 101, 4385, 1762,  ...,    0,    0,    0],
        [ 101, 1278, 4495,  ...,    0,    0,    0],
        [ 101, 1278, 4495,  ...,    0,    0,    0],
        ...,
        [ 101, 6435, 7309,  ...,    0,    0,    0],
        [ 101, 2769,  754,  ..., 3690, 5101,  102],
        [ 101, 6941,  712,  ..., 3300,  671,  102]])
 
2021-08-23 19:51:22 train.py INFO token_ids shape: torch.Size([16, 128])
 
2021-08-23 19:51:22 train.py INFO attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]])

2021-08-23 19:51:22 train.py INFO token_type_ids: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]])

2021-08-23 19:51:22 train.py INFO labels: tensor([ 5,  4,  2,  0,  7,  3,  7,  8,  0,  9,  1,  7,  2,  3, 10,  9])

2021-08-23 19:51:22 train.py INFO labels shape: torch.Size([16])

2021-08-23 19:52:46 train.py INFO result: 
              precision    recall  f1-score   support

          男科     0.9904    0.8697    0.9261       591
         皮肤科     0.7961    0.9480    0.8654       173
          其它     0.5400    0.6667    0.5967       162
          妇科     0.8000    0.8333    0.8163        72
       心血管内科     0.9259    0.7463    0.8264        67
        耳鼻喉科     0.7949    0.6078    0.6889        51
        消化内科     0.8391    0.8690    0.8538        84
        小儿内科     0.8182    0.6316    0.7129       114
        呼吸内科     0.7202    0.8832    0.7934       137
        内分泌科     0.7681    0.8413    0.8030        63
        神经内科     0.6267    0.7121    0.6667        66

    accuracy                         0.8184      1580
   macro avg     0.7836    0.7826    0.7772      1580
weighted avg     0.8373    0.8184    0.8223      1580

2021-08-23 19:52:46 train.py INFO Confusion matrix: 
[[514  19  36  10   1   0   1   0   0   2   8]
 [  1 164   7   0   0   0   0   0   1   0   0]
 [  2  15 108   3   0   2   7   6   6   6   7]
 [  0   2   8  60   0   0   1   0   0   1   0]
 [  1   1   2   1  50   0   0   0   2   6   4]
 [  0   0   4   0   0  31   0   0  12   0   4]
 [  0   0   8   0   0   0  73   0   3   0   0]
 [  0   2  11   0   0   1   3  72  23   1   1]
 [  0   0   1   1   0   5   1   7 121   0   1]
 [  1   0   6   0   0   0   0   0   0  53   3]
 [  0   3   9   0   3   0   1   3   0   0  47]]
2021-08-23 19:52:48 train.py INFO Iter:4000, Train Loss:0.6568, Train Acc:81.25%, Val Loss:0.6095, Val Acc:81.84%, Time:0:18:06 *
2021-08-23 19:56:50 train.py INFO Epoch [5/30]
2021-08-23 19:56:50 train.py INFO token_ids: tensor([[ 101, 1234, 6629,  ...,    0,    0,    0],
        [ 101, 2769, 1036,  ..., 6444, 4415,  102],
        [ 101, 2111, 2094,  ...,    0,    0,    0],
        ...,
        [ 101,  722, 1184,  ...,    0,    0,    0],
        [ 101, 3193, 3786,  ...,    0,    0,    0],
        [ 101, 2769,  671,  ...,    0,    0,    0]])
 
2021-08-23 19:56:50 train.py INFO token_ids shape: torch.Size([16, 79])
 
2021-08-23 19:56:50 train.py INFO attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]])

2021-08-23 19:56:50 train.py INFO token_type_ids: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]])

2021-08-23 19:56:50 train.py INFO labels: tensor([ 0,  7,  7,  1,  0,  5,  8,  4,  8,  1,  7,  8, 10,  1,  0,  2])

2021-08-23 19:56:50 train.py INFO labels shape: torch.Size([16])

2021-08-23 19:57:14 train.py INFO result: 
              precision    recall  f1-score   support

          男科     0.9886    0.8782    0.9301       591
         皮肤科     0.8634    0.9133    0.8876       173
          其它     0.5323    0.6111    0.5690       162
          妇科     0.8158    0.8611    0.8378        72
       心血管内科     0.8281    0.7910    0.8092        67
        耳鼻喉科     0.8222    0.7255    0.7708        51
        消化内科     0.8261    0.9048    0.8636        84
        小儿内科     0.6376    0.8333    0.7224       114
        呼吸内科     0.7907    0.7445    0.7669       137
        内分泌科     0.7215    0.9048    0.8028        63
        神经内科     0.7692    0.6061    0.6780        66

    accuracy                         0.8215      1580
   macro avg     0.7814    0.7976    0.7853      1580
weighted avg     0.8371    0.8215    0.8257      1580

2021-08-23 19:57:14 train.py INFO Confusion matrix: 
[[519   9  41   6   2   0   1   2   0   6   5]
 [  2 158   9   2   0   0   0   1   0   0   1]
 [  3  11  99   3   2   2   9  18   4   8   3]
 [  1   1   6  62   0   0   1   0   0   1   0]
 [  0   1   2   1  53   0   0   1   2   6   1]
 [  0   0   4   0   0  37   0   0   9   0   1]
 [  0   0   5   0   1   0  76   0   2   0   0]
 [  0   1   3   0   0   1   3  95  10   0   1]
 [  0   0   2   1   2   4   1  25 102   0   0]
 [  0   0   5   0   0   0   0   1   0  57   0]
 [  0   2  10   1   4   1   1   6   0   1  40]]
2021-08-23 19:57:16 train.py INFO Iter:5000, Train Loss:0.8857, Train Acc:75.00%, Val Loss:0.6676, Val Acc:82.15%, Time:0:22:34 *
2021-08-23 20:01:42 train.py INFO result: 
              precision    recall  f1-score   support

          男科     0.9869    0.8934    0.9378       591
         皮肤科     0.8214    0.9306    0.8726       173
          其它     0.6197    0.5432    0.5789       162
          妇科     0.7619    0.8889    0.8205        72
       心血管内科     0.9138    0.7910    0.8480        67
        耳鼻喉科     0.7234    0.6667    0.6939        51
        消化内科     0.7938    0.9167    0.8508        84
        小儿内科     0.6791    0.7982    0.7339       114
        呼吸内科     0.7500    0.7664    0.7581       137
        内分泌科     0.7571    0.8413    0.7970        63
        神经内科     0.6234    0.7273    0.6713        66

    accuracy                         0.8241      1580
   macro avg     0.7664    0.7967    0.7784      1580
weighted avg     0.8319    0.8241    0.8252      1580

2021-08-23 20:01:42 train.py INFO Confusion matrix: 
[[528  15  24  11   0   0   2   1   0   2   8]
 [  2 161   5   1   0   0   0   0   1   0   3]
 [  3  15  88   6   0   3  12  11   7   7  10]
 [  0   1   5  64   0   0   1   0   0   1   0]
 [  0   1   2   1  53   1   0   0   1   6   2]
 [  0   0   2   0   0  34   0   2  12   0   1]
 [  0   0   3   0   0   0  77   0   3   1   0]
 [  0   1   4   0   0   3   2  91  11   0   2]
 [  1   0   0   1   1   3   2  24 105   0   0]
 [  1   0   5   0   0   0   0   1   0  53   3]
 [  0   2   4   0   4   3   1   4   0   0  48]]
2021-08-23 20:01:45 train.py INFO Iter:6000, Train Loss:0.3450, Train Acc:93.75%, Val Loss:0.5746, Val Acc:82.41%, Time:0:27:03 *
2021-08-23 20:02:30 train.py INFO Epoch [6/30]
2021-08-23 20:02:30 train.py INFO token_ids: tensor([[ 101, 2769, 3300,  ...,    0,    0,    0],
        [ 101, 5558, 4624,  ...,    0,    0,    0],
        [ 101, 3297, 6818,  ...,    0,    0,    0],
        ...,
        [ 101, 5131, 2228,  ...,    0,    0,    0],
        [ 101, 1495, 1644,  ...,    0,    0,    0],
        [ 101,  872, 1962,  ...,    0,    0,    0]])
 
2021-08-23 20:02:30 train.py INFO token_ids shape: torch.Size([16, 95])
 
2021-08-23 20:02:30 train.py INFO attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]])

2021-08-23 20:02:30 train.py INFO token_type_ids: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]])

2021-08-23 20:02:30 train.py INFO labels: tensor([ 2,  1, 10,  2,  9,  7,  7,  8,  3,  7,  4,  9,  4,  9,  8,  9])

2021-08-23 20:02:30 train.py INFO labels shape: torch.Size([16])

2021-08-23 20:06:11 train.py INFO result: 
              precision    recall  f1-score   support

          男科     0.9854    0.9137    0.9482       591
         皮肤科     0.8325    0.9191    0.8736       173
          其它     0.5765    0.6049    0.5904       162
          妇科     0.8000    0.8889    0.8421        72
       心血管内科     0.8909    0.7313    0.8033        67
        耳鼻喉科     0.6441    0.7451    0.6909        51
        消化内科     0.7624    0.9167    0.8324        84
        小儿内科     0.6531    0.8421    0.7356       114
        呼吸内科     0.8411    0.6569    0.7377       137
        内分泌科     0.7465    0.8413    0.7910        63
        神经内科     0.7843    0.6061    0.6838        66

    accuracy                         0.8253      1580
   macro avg     0.7742    0.7878    0.7754      1580
weighted avg     0.8370    0.8253    0.8270      1580

2021-08-23 20:06:11 train.py INFO Confusion matrix: 
[[540  12  22   8   0   0   2   1   0   3   3]
 [  2 159   8   1   0   1   0   1   0   0   1]
 [  3  15  98   4   1   3  13  13   2   7   3]
 [  0   1   5  64   0   0   2   0   0   0   0]
 [  0   1   4   1  49   1   1   1   1   7   1]
 [  0   0   4   0   0  38   0   1   7   0   1]
 [  0   0   4   0   0   0  77   1   2   0   0]
 [  0   1   5   0   0   4   2  96   5   0   1]
 [  2   0   3   1   1  11   4  25  90   0   0]
 [  1   0   8   0   0   0   0   0   0  53   1]
 [  0   2   9   1   4   1   0   8   0   1  40]]
2021-08-23 20:06:13 train.py INFO Iter:7000, Train Loss:0.6413, Train Acc:81.25%, Val Loss:0.5958, Val Acc:82.53%, Time:0:31:31 *
2021-08-23 20:08:00 train.py INFO Epoch [7/30]
2021-08-23 20:08:00 train.py INFO token_ids: tensor([[ 101, 3680, 3613,  ...,    0,    0,    0],
        [ 101, 5314, 2458,  ...,    0,    0,    0],
        [ 101, 3118, 3698,  ...,    0,    0,    0],
        ...,
        [ 101, 2157, 3184,  ...,    0,    0,    0],
        [ 101, 1495, 1644,  ...,    0,    0,    0],
        [ 101, 1278, 4495,  ...,    0,    0,    0]])
 
2021-08-23 20:08:00 train.py INFO token_ids shape: torch.Size([16, 117])
 
2021-08-23 20:08:00 train.py INFO attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]])

2021-08-23 20:08:00 train.py INFO token_type_ids: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]])

2021-08-23 20:08:00 train.py INFO labels: tensor([ 2,  6,  8,  7,  8,  1,  6, 10,  5,  1,  8,  1,  4,  4,  8,  4])

2021-08-23 20:08:00 train.py INFO labels shape: torch.Size([16])

2021-08-23 20:10:39 train.py INFO result: 
              precision    recall  f1-score   support

          男科     0.9817    0.9052    0.9419       591
         皮肤科     0.8325    0.9191    0.8736       173
          其它     0.6194    0.5926    0.6057       162
          妇科     0.8049    0.9167    0.8571        72
       心血管内科     0.6552    0.8507    0.7403        67
        耳鼻喉科     0.8333    0.6863    0.7527        51
        消化内科     0.7327    0.8810    0.8000        84
        小儿内科     0.8315    0.6491    0.7291       114
        呼吸内科     0.6839    0.8686    0.7653       137
        内分泌科     0.8167    0.7778    0.7967        63
        神经内科     0.7407    0.6061    0.6667        66

    accuracy                         0.8253      1580
   macro avg     0.7757    0.7866    0.7754      1580
weighted avg     0.8349    0.8253    0.8259      1580

2021-08-23 20:10:39 train.py INFO Confusion matrix: 
[[535  13  20   7   4   0   5   1   0   3   3]
 [  3 159   3   2   0   0   1   0   3   0   2]
 [  5  13  96   4   9   1  11   5   9   5   4]
 [  0   1   4  66   0   0   1   0   0   0   0]
 [  0   1   2   1  57   0   0   0   3   3   0]
 [  0   0   3   0   1  35   0   0  11   0   1]
 [  0   0   4   1   1   0  74   0   4   0   0]
 [  0   1   9   0   0   1   4  74  24   0   1]
 [  1   0   0   1   1   3   3   8 119   0   1]
 [  1   0   6   0   4   1   0   0   0  49   2]
 [  0   3   8   0  10   1   2   1   1   0  40]]
2021-08-23 20:10:39 train.py INFO Iter:8000, Train Loss:0.0674, Train Acc:100.00%, Val Loss:0.6320, Val Acc:82.53%, Time:0:35:58 
2021-08-23 20:13:26 train.py INFO Epoch [8/30]
2021-08-23 20:13:26 train.py INFO token_ids: tensor([[ 101, 1624, 2094,  ...,    0,    0,    0],
        [ 101, 1278, 4495,  ...,    0,    0,    0],
        [ 101, 7481, 6956,  ...,    0,    0,    0],
        ...,
        [ 101,  782, 3837,  ...,    0,    0,    0],
        [ 101, 2682, 2990,  ...,    0,    0,    0],
        [ 101, 2644, 1962,  ...,    0,    0,    0]])
 
2021-08-23 20:13:26 train.py INFO token_ids shape: torch.Size([16, 128])
 
2021-08-23 20:13:26 train.py INFO attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]])

2021-08-23 20:13:26 train.py INFO token_type_ids: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]])

2021-08-23 20:13:26 train.py INFO labels: tensor([ 8,  8,  1,  7,  6,  2,  0,  1,  8,  1,  9, 10,  3,  3,  0,  6])

2021-08-23 20:13:26 train.py INFO labels shape: torch.Size([16])

2021-08-23 20:15:06 train.py INFO result: 
              precision    recall  f1-score   support

          男科     0.9783    0.9154    0.9458       591
         皮肤科     0.8681    0.9133    0.8901       173
          其它     0.5463    0.6914    0.6104       162
          妇科     0.8769    0.7917    0.8321        72
       心血管内科     0.8182    0.8060    0.8120        67
        耳鼻喉科     0.6786    0.7451    0.7103        51
        消化内科     0.8276    0.8571    0.8421        84
        小儿内科     0.8630    0.5526    0.6738       114
        呼吸内科     0.7329    0.8613    0.7919       137
        内分泌科     0.8421    0.7619    0.8000        63
        神经内科     0.6800    0.7727    0.7234        66

    accuracy                         0.8304      1580
   macro avg     0.7920    0.7880    0.7847      1580
weighted avg     0.8454    0.8304    0.8333      1580

2021-08-23 20:15:06 train.py INFO Confusion matrix: 
[[541  10  28   3   0   0   1   1   0   2   5]
 [  3 158   7   1   0   0   0   0   1   0   3]
 [  5   9 112   3   2   4   7   2   6   4   8]
 [  0   1  11  57   0   1   1   0   0   1   0]
 [  0   1   6   0  54   0   0   0   2   2   2]
 [  0   0   5   0   0  38   0   0   7   0   1]
 [  1   0   6   0   3   0  72   0   2   0   0]
 [  0   2  14   0   0   5   4  63  24   0   2]
 [  1   0   0   1   0   7   2   7 118   0   1]
 [  1   0   8   0   4   0   0   0   0  48   2]
 [  1   1   8   0   3   1   0   0   1   0  51]]
2021-08-23 20:15:08 train.py INFO Iter:9000, Train Loss:0.5847, Train Acc:87.50%, Val Loss:0.6247, Val Acc:83.04%, Time:0:40:26 *
2021-08-23 20:18:56 train.py INFO Epoch [9/30]
2021-08-23 20:18:56 train.py INFO token_ids: tensor([[ 101, 1928, 4649,  ...,    0,    0,    0],
        [ 101, 3118, 1333,  ...,    0,    0,    0],
        [ 101, 7346, 6887,  ...,    0,    0,    0],
        ...,
        [ 101, 4385, 1762,  ...,    0,    0,    0],
        [ 101, 1278, 4495,  ...,    0,    0,    0],
        [ 101, 1928, 2523,  ...,    0,    0,    0]])
 
2021-08-23 20:18:56 train.py INFO token_ids shape: torch.Size([16, 128])
 
2021-08-23 20:18:56 train.py INFO attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]])

2021-08-23 20:18:56 train.py INFO token_type_ids: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]])

2021-08-23 20:18:56 train.py INFO labels: tensor([1, 2, 3, 1, 2, 1, 3, 9, 7, 0, 8, 7, 3, 7, 3, 2])

2021-08-23 20:18:56 train.py INFO labels shape: torch.Size([16])

2021-08-23 20:19:36 train.py INFO result: 
              precision    recall  f1-score   support

          男科     0.9805    0.9357    0.9576       591
         皮肤科     0.8283    0.9480    0.8841       173
          其它     0.6522    0.5556    0.6000       162
          妇科     0.8052    0.8611    0.8322        72
       心血管内科     0.7260    0.7910    0.7571        67
        耳鼻喉科     0.8095    0.6667    0.7312        51
        消化内科     0.8571    0.8571    0.8571        84
        小儿内科     0.8298    0.6842    0.7500       114
        呼吸内科     0.7160    0.8832    0.7908       137
        内分泌科     0.6883    0.8413    0.7571        63
        神经内科     0.7500    0.7273    0.7385        66

    accuracy                         0.8405      1580
   macro avg     0.7857    0.7956    0.7869      1580
weighted avg     0.8442    0.8405    0.8394      1580

2021-08-23 20:19:36 train.py INFO Confusion matrix: 
[[553  13   9   5   3   0   1   0   0   2   5]
 [  3 164   2   1   0   0   0   0   2   1   0]
 [  4  16  90   7   7   3   6   5   8  10   6]
 [  1   1   4  62   0   0   1   0   0   3   0]
 [  0   1   2   1  53   0   0   0   2   7   1]
 [  0   0   4   0   1  34   0   1  10   0   1]
 [  1   0   7   0   2   0  72   0   2   0   0]
 [  0   1   9   0   0   1   2  78  22   0   1]
 [  1   0   1   1   1   3   1   8 121   0   0]
 [  1   0   6   0   1   0   0   0   0  53   2]
 [  0   2   4   0   5   1   1   2   2   1  48]]
2021-08-23 20:19:37 train.py INFO Iter:10000, Train Loss:0.0149, Train Acc:100.00%, Val Loss:0.6294, Val Acc:84.05%, Time:0:44:56 *
2021-08-23 20:24:04 train.py INFO result: 
              precision    recall  f1-score   support

          男科     0.9870    0.8985    0.9407       591
         皮肤科     0.8757    0.8555    0.8655       173
          其它     0.4571    0.7901    0.5792       162
          妇科     0.8955    0.8333    0.8633        72
       心血管内科     0.9333    0.6269    0.7500        67
        耳鼻喉科     0.8684    0.6471    0.7416        51
        消化内科     0.8276    0.8571    0.8421        84
        小儿内科     0.8256    0.6228    0.7100       114
        呼吸内科     0.7197    0.8248    0.7687       137
        内分泌科     0.7794    0.8413    0.8092        63
        神经内科     0.7333    0.5000    0.5946        66

    accuracy                         0.8127      1580
   macro avg     0.8093    0.7543    0.7695      1580
weighted avg     0.8480    0.8127    0.8208      1580

2021-08-23 20:24:04 train.py INFO Confusion matrix: 
[[531  10  38   4   0   0   1   0   0   2   5]
 [  2 148  21   1   0   0   0   0   0   0   1]
 [  2   8 128   2   0   2   6   1   5   5   3]
 [  0   1  10  60   0   0   1   0   0   0   0]
 [  0   1  11   0  42   0   1   0   4   7   1]
 [  0   0   7   0   0  33   0   0  10   0   1]
 [  0   0   9   0   0   0  72   0   3   0   0]
 [  0   1  18   0   0   0   3  71  21   0   0]
 [  1   0   6   0   0   3   2  12 113   0   0]
 [  1   0   8   0   0   0   0   0   0  53   1]
 [  1   0  24   0   3   0   1   2   1   1  33]]
2021-08-23 20:24:04 train.py INFO Iter:11000, Train Loss:0.2048, Train Acc:87.50%, Val Loss:0.7282, Val Acc:81.27%, Time:0:49:22 
2021-08-23 20:24:33 train.py INFO Epoch [10/30]
2021-08-23 20:24:33 train.py INFO token_ids: tensor([[ 101, 3070, 1922,  ...,    0,    0,    0],
        [ 101, 5131, 2228,  ...,    0,    0,    0],
        [ 101, 1155, 1278,  ...,    0,    0,    0],
        ...,
        [ 101, 4578, 7599,  ...,    0,    0,    0],
        [ 101, 2697, 1088,  ...,    0,    0,    0],
        [ 101, 1278, 4495,  ...,    0,    0,    0]])
 
2021-08-23 20:24:33 train.py INFO token_ids shape: torch.Size([16, 120])
 
2021-08-23 20:24:33 train.py INFO attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]])

2021-08-23 20:24:33 train.py INFO token_type_ids: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]])

2021-08-23 20:24:33 train.py INFO labels: tensor([0, 9, 6, 0, 1, 6, 3, 2, 1, 1, 4, 9, 0, 2, 5, 8])

2021-08-23 20:24:33 train.py INFO labels shape: torch.Size([16])

2021-08-23 20:28:28 train.py INFO result: 
              precision    recall  f1-score   support

          男科     0.9853    0.9052    0.9436       591
         皮肤科     0.8511    0.9249    0.8864       173
          其它     0.5906    0.5432    0.5659       162
          妇科     0.7241    0.8750    0.7925        72
       心血管内科     0.8571    0.7164    0.7805        67
        耳鼻喉科     0.6552    0.7451    0.6972        51
        消化内科     0.7917    0.9048    0.8444        84
        小儿内科     0.7900    0.6930    0.7383       114
        呼吸内科     0.6867    0.8321    0.7525       137
        内分泌科     0.7027    0.8254    0.7591        63
        神经内科     0.7460    0.7121    0.7287        66

    accuracy                         0.8228      1580
   macro avg     0.7619    0.7888    0.7717      1580
weighted avg     0.8306    0.8228    0.8239      1580

2021-08-23 20:28:28 train.py INFO Confusion matrix: 
[[535  11  24   9   0   0   2   1   2   2   5]
 [  2 160   5   3   0   0   0   0   1   1   1]
 [  3  12  88   7   3   6  10   7  11  10   5]
 [  0   1   5  63   0   0   1   0   1   1   0]
 [  0   1   4   2  48   1   1   0   4   5   1]
 [  0   0   3   0   0  38   0   1   8   0   1]
 [  0   0   4   1   0   0  76   0   3   0   0]
 [  0   1   7   0   0   3   3  79  19   1   1]
 [  1   0   0   1   0   8   2  11 114   0   0]
 [  1   0   6   0   2   0   0   0   0  52   2]
 [  1   2   3   1   3   2   1   1   3   2  47]]
2021-08-23 20:28:28 train.py INFO Iter:12000, Train Loss:0.0854, Train Acc:100.00%, Val Loss:0.6951, Val Acc:82.28%, Time:0:53:47 
2021-08-23 20:29:57 train.py INFO Epoch [11/30]
2021-08-23 20:29:57 train.py INFO token_ids: tensor([[ 101, 1278, 4495,  ...,    0,    0,    0],
        [ 101, 4895, 2460,  ...,    0,    0,    0],
        [ 101,  860, 3466,  ...,    0,    0,    0],
        ...,
        [ 101, 1157, 2458,  ...,    0,    0,    0],
        [ 101, 7770, 6117,  ...,    0,    0,    0],
        [ 101, 1278, 4495,  ...,    0,    0,    0]])
 
2021-08-23 20:29:57 train.py INFO token_ids shape: torch.Size([16, 123])
 
2021-08-23 20:29:57 train.py INFO attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]])

2021-08-23 20:29:57 train.py INFO token_type_ids: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]])

2021-08-23 20:29:57 train.py INFO labels: tensor([ 3,  0,  2, 10,  0,  7,  1,  8,  2,  1,  6,  2,  8,  7,  4,  6])

2021-08-23 20:29:57 train.py INFO labels shape: torch.Size([16])

2021-08-23 20:32:52 train.py INFO result: 
              precision    recall  f1-score   support

          男科     0.9836    0.9137    0.9474       591
         皮肤科     0.8516    0.8960    0.8732       173
          其它     0.5684    0.6667    0.6136       162
          妇科     0.8493    0.8611    0.8552        72
       心血管内科     0.8868    0.7015    0.7833        67
        耳鼻喉科     0.7451    0.7451    0.7451        51
        消化内科     0.8333    0.8333    0.8333        84
        小儿内科     0.8353    0.6228    0.7136       114
        呼吸内科     0.7000    0.8686    0.7752       137
        内分泌科     0.6353    0.8571    0.7297        63
        神经内科     0.7931    0.6970    0.7419        66

    accuracy                         0.8291      1580
   macro avg     0.7893    0.7875    0.7829      1580
weighted avg     0.8435    0.8291    0.8322      1580

2021-08-23 20:32:52 train.py INFO Confusion matrix: 
[[540  10  27   4   0   0   1   0   1   5   3]
 [  3 155   7   1   0   0   0   0   1   4   2]
 [  3  12 108   3   2   3   6   4  10   8   3]
 [  0   1   5  62   0   0   1   0   0   3   0]
 [  0   1   7   2  47   0   1   0   2   6   1]
 [  0   0   5   0   0  38   0   0   7   0   1]
 [  1   0   8   0   0   0  70   0   3   2   0]
 [  0   1   9   0   0   3   2  71  26   1   1]
 [  1   0   0   1   0   6   2   8 119   0   0]
 [  1   0   7   0   0   0   0   0   0  54   1]
 [  0   2   7   0   4   1   1   2   1   2  46]]
2021-08-23 20:32:52 train.py INFO Iter:13000, Train Loss:0.1340, Train Acc:93.75%, Val Loss:0.7784, Val Acc:82.91%, Time:0:58:11 
2021-08-23 20:35:23 train.py INFO Epoch [12/30]
2021-08-23 20:35:23 train.py INFO token_ids: tensor([[ 101, 1596, 2622,  ...,    0,    0,    0],
        [ 101,  722, 1184,  ...,    0,    0,    0],
        [ 101, 4635, 5682,  ...,    0,    0,    0],
        ...,
        [ 101, 2552, 5552,  ...,    0,    0,    0],
        [ 101, 3342, 1278,  ..., 7391, 4578,  102],
        [ 101, 7755, 2835,  ...,    0,    0,    0]])
 
2021-08-23 20:35:23 train.py INFO token_ids shape: torch.Size([16, 128])
 
2021-08-23 20:35:23 train.py INFO attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]])

2021-08-23 20:35:23 train.py INFO token_type_ids: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]])

2021-08-23 20:35:23 train.py INFO labels: tensor([ 7,  9,  1,  8,  7,  4,  0,  9,  6,  0, 10,  3,  2,  2,  6,  2])

2021-08-23 20:35:23 train.py INFO labels shape: torch.Size([16])

2021-08-23 20:37:17 train.py INFO result: 
              precision    recall  f1-score   support

          男科     0.9852    0.9002    0.9408       591
         皮肤科     0.8308    0.9364    0.8804       173
          其它     0.5432    0.5432    0.5432       162
          妇科     0.8182    0.8750    0.8456        72
       心血管内科     0.7647    0.7761    0.7704        67
        耳鼻喉科     0.5833    0.6863    0.6306        51
        消化内科     0.7596    0.9405    0.8404        84
        小儿内科     0.8452    0.6228    0.7172       114
        呼吸内科     0.7647    0.7591    0.7619       137
        内分泌科     0.7797    0.7302    0.7541        63
        神经内科     0.6211    0.8939    0.7329        66

    accuracy                         0.8171      1580
   macro avg     0.7542    0.7876    0.7652      1580
weighted avg     0.8284    0.8171    0.8187      1580

2021-08-23 20:37:17 train.py INFO Confusion matrix: 
[[532  12  25   7   1   0   3   0   0   2   9]
 [  3 162   3   0   0   1   1   0   0   0   3]
 [  3  17  88   5   6   4  11   4   3   7  14]
 [  0   1   7  63   0   0   1   0   0   0   0]
 [  0   1   4   1  52   1   1   0   1   4   2]
 [  0   0   5   0   1  35   0   1   8   0   1]
 [  0   0   4   0   0   1  79   0   0   0   0]
 [  0   1  11   0   0   3   5  71  20   0   3]
 [  1   0   4   1   1  15   2   8 104   0   1]
 [  1   0   8   0   4   0   1   0   0  46   3]
 [  0   1   3   0   3   0   0   0   0   0  59]]
2021-08-23 20:37:17 train.py INFO Iter:14000, Train Loss:0.0218, Train Acc:100.00%, Val Loss:0.7834, Val Acc:81.71%, Time:1:02:36 
2021-08-23 20:40:48 train.py INFO Epoch [13/30]
2021-08-23 20:40:48 train.py INFO token_ids: tensor([[ 101,  872, 1962,  ...,    0,    0,    0],
        [ 101, 4635, 4626,  ...,    0,    0,    0],
        [ 101, 4567, 2658,  ...,    0,    0,    0],
        ...,
        [ 101, 1278, 4495,  ..., 5549,  897,  102],
        [ 101, 4129, 2900,  ...,    0,    0,    0],
        [ 101, 1383, 1278,  ...,    0,    0,    0]])
 
2021-08-23 20:40:48 train.py INFO token_ids shape: torch.Size([16, 128])
 
2021-08-23 20:40:48 train.py INFO attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]])

2021-08-23 20:40:48 train.py INFO token_type_ids: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]])

2021-08-23 20:40:48 train.py INFO labels: tensor([1, 1, 1, 2, 6, 1, 1, 3, 4, 1, 1, 2, 2, 9, 1, 0])

2021-08-23 20:40:48 train.py INFO labels shape: torch.Size([16])

2021-08-23 20:41:42 train.py INFO result: 
              precision    recall  f1-score   support

          男科     0.9803    0.9239    0.9512       591
         皮肤科     0.8290    0.9249    0.8743       173
          其它     0.5511    0.5988    0.5740       162
          妇科     0.8400    0.8750    0.8571        72
       心血管内科     0.8361    0.7612    0.7969        67
        耳鼻喉科     0.7907    0.6667    0.7234        51
        消化内科     0.8202    0.8690    0.8439        84
        小儿内科     0.7266    0.8158    0.7686       114
        呼吸内科     0.7857    0.8029    0.7942       137
        内分泌科     0.7000    0.7778    0.7368        63
        神经内科     0.8333    0.6061    0.7018        66

    accuracy                         0.8329      1580
   macro avg     0.7903    0.7838    0.7838      1580
weighted avg     0.8401    0.8329    0.8345      1580

2021-08-23 20:41:42 train.py INFO Confusion matrix: 
[[546   9  24   5   0   0   1   1   0   3   2]
 [  4 160   5   1   0   0   0   0   1   1   1]
 [  3  17  97   5   3   2   8   7   8  10   2]
 [  0   1   5  63   0   1   1   0   0   1   0]
 [  0   1   7   0  51   0   1   1   2   3   1]
 [  0   0   7   0   0  34   0   1   8   0   1]
 [  0   1   6   0   0   0  73   0   3   1   0]
 [  0   1   9   0   0   1   2  93   8   0   0]
 [  1   0   1   1   0   4   2  18 110   0   0]
 [  1   0   6   0   5   0   1   0   0  49   1]
 [  2   3   9   0   2   1   0   7   0   2  40]]
2021-08-23 20:41:42 train.py INFO Iter:15000, Train Loss:0.0083, Train Acc:100.00%, Val Loss:0.7543, Val Acc:83.29%, Time:1:07:00 
2021-08-23 20:46:08 train.py INFO result: 
              precision    recall  f1-score   support

          男科     0.9926    0.9019    0.9450       591
         皮肤科     0.8291    0.9538    0.8871       173
          其它     0.5723    0.6111    0.5910       162
          妇科     0.7927    0.9028    0.8442        72
       心血管内科     0.8065    0.7463    0.7752        67
        耳鼻喉科     0.7500    0.6471    0.6947        51
        消化内科     0.8333    0.8333    0.8333        84
        小儿内科     0.7928    0.7719    0.7822       114
        呼吸内科     0.7552    0.7883    0.7714       137
        内分泌科     0.7639    0.8730    0.8148        63
        神经内科     0.7397    0.8182    0.7770        66

    accuracy                         0.8354      1580
   macro avg     0.7844    0.8043    0.7924      1580
weighted avg     0.8436    0.8354    0.8376      1580

2021-08-23 20:46:08 train.py INFO Confusion matrix: 
[[533  16  29   5   0   0   1   0   0   2   5]
 [  0 165   6   1   0   0   0   1   0   0   0]
 [  1  13  99   9   4   3   6   5   5   9   8]
 [  0   2   4  65   0   0   1   0   0   0   0]
 [  0   1   4   1  50   0   1   0   2   6   2]
 [  0   0   4   0   0  33   0   4   9   0   1]
 [  0   0  11   0   1   0  70   0   2   0   0]
 [  0   1   5   0   0   2   2  88  15   0   1]
 [  2   0   2   1   3   6   2  12 108   0   1]
 [  1   0   5   0   1   0   0   0   0  55   1]
 [  0   1   4   0   3   0   1   1   2   0  54]]
2021-08-23 20:46:08 train.py INFO Iter:16000, Train Loss:0.1707, Train Acc:87.50%, Val Loss:0.7774, Val Acc:83.54%, Time:1:11:27 ````
2021-08-23 20:46:22 train.py INFO Epoch [14/30]
2021-08-23 20:46:22 train.py INFO token_ids: tensor([[ 101, 1278, 4495,  ...,    0,    0,    0],
        [ 101, 5558,  677,  ...,    0,    0,    0],
        [ 101, 3680, 3613,  ...,    0,    0,    0],
        ...,
        [ 101, 3299, 5307,  ...,    0,    0,    0],
        [ 101, 5439, 1495,  ...,    0,    0,    0],
        [ 101, 1278, 4495,  ...,    0,    0,    0]])
 
2021-08-23 20:46:22 train.py INFO token_ids shape: torch.Size([16, 128])
 
2021-08-23 20:46:22 train.py INFO attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]])

2021-08-23 20:46:22 train.py INFO token_type_ids: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]])

2021-08-23 20:46:22 train.py INFO labels: tensor([ 2,  1,  7,  7,  1,  1,  1,  1,  1,  2,  7, 10,  1,  3,  8,  3])

2021-08-23 20:46:22 train.py INFO labels shape: torch.Size([16])

2021-08-23 20:50:33 train.py INFO result: 
              precision    recall  f1-score   support

          男科     0.9924    0.8832    0.9346       591
         皮肤科     0.8929    0.8671    0.8798       173
          其它     0.5021    0.7469    0.6005       162
          妇科     0.8289    0.8750    0.8514        72
       心血管内科     0.7200    0.8060    0.7606        67
        耳鼻喉科     0.7407    0.7843    0.7619        51
        消化内科     0.8353    0.8452    0.8402        84
        小儿内科     0.8043    0.6491    0.7184       114
        呼吸内科     0.7215    0.8321    0.7729       137
        内分泌科     0.8200    0.6508    0.7257        63
        神经内科     0.7636    0.6364    0.6942        66

    accuracy                         0.8177      1580
   macro avg     0.7838    0.7796    0.7764      1580
weighted avg     0.8423    0.8177    0.8246      1580

2021-08-23 20:50:33 train.py INFO Confusion matrix: 
[[522   6  42   7   2   0   1   1   1   2   7]
 [  2 150  19   0   1   0   0   0   1   0   0]
 [  1   7 121   5   3   3   6   1   8   6   1]
 [  0   1   7  63   0   0   1   0   0   0   0]
 [  0   1   7   0  54   0   0   1   2   1   1]
 [  0   0   2   0   0  40   0   1   8   0   0]
 [  0   0  10   0   0   0  71   0   3   0   0]
 [  0   1  13   0   0   4   3  74  18   0   1]
 [  1   0   2   1   0   6   2  11 114   0   0]
 [  0   1   8   0   9   0   0   1   0  41   3]
 [  0   1  10   0   6   1   1   2   3   0  42]]
2021-08-23 20:50:33 train.py INFO Iter:17000, Train Loss:0.1332, Train Acc:93.75%, Val Loss:0.8347, Val Acc:81.77%, Time:1:15:51 
2021-08-23 20:51:48 train.py INFO Epoch [15/30]
2021-08-23 20:51:48 train.py INFO token_ids: tensor([[ 101, 2769, 3300,  ...,    0,    0,    0],
        [ 101, 2347, 5307,  ...,    0,    0,    0],
        [ 101, 2644, 1962,  ...,    0,    0,    0],
        ...,
        [ 101, 4578, 7599,  ...,    0,    0,    0],
        [ 101, 3291, 2399,  ...,    0,    0,    0],
        [ 101, 4649, 5502,  ...,    0,    0,    0]])
 
2021-08-23 20:51:48 train.py INFO token_ids shape: torch.Size([16, 128])
 
2021-08-23 20:51:48 train.py INFO attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]])

2021-08-23 20:51:48 train.py INFO token_type_ids: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]])

2021-08-23 20:51:48 train.py INFO labels: tensor([6, 6, 4, 2, 1, 7, 4, 3, 3, 0, 8, 1, 0, 9, 9, 2])

2021-08-23 20:51:48 train.py INFO labels shape: torch.Size([16])

